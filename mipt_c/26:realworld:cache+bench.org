#+TITLE: Семниар 7.1. Кеши и немного о бенчмаркинге 
#+AUTHOR: idsyr
#+STARTUP: showeverything 
#+OPTIONS: toc:2




* As if rule и оптимизации (00:00) 
** Немного о бенчмаркинге
- Как выяснить сколько времени занимает цикл до N*M?
#+begin_src cpp
struct timespec t1, t2;
clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &t1);
for(int i = 0; i < N; ++i)
  for (int j = 0; j < M; ++j){
    // (+) 
  }
clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &t2);
#+end_src
- Это будет всегда показывать ноль секунд
- Компилятор выбросит 
** As-if rule
- Компилятор всегда работает так, чтобы наблюдаемое поведение оставалось таким, как если бы (as if) он не работал
- Что представляет собой наблюдаемое поведение?
 - Accesses through volatile gvalues
 - Data written into files
 - The input and output dynamics of interactive devices
- Компилятор имеет право делать с программой почти что угодно пока наблюдаемое поведение то же
- Это дает достаточную свободу оптимизаторам
** Компиляторы консервативны
*** Решение 1
- Каждый С файл транслируется отдельно -> при вызове функции из другого модуля его наблюдаемое поведение не оценить
- И если добавить вызов функции компилятор ничего не сделает: он не уверен нет ли в другом модуле побочных эффектов при этом вызове
- Проблема в том что вызов добавит нам оверхеда (call)
*** Решение 2
- Использовать volatile
- Проблема в том что volatile не соптимизируется на регистр и чтение добавит оверхеад
*** Решение 3
- Компиляторы не понимают семантики ассемблера
#+begin_src cpp
asm("": :"r"(i),"r"(j));
#+end_src
- Это решает проблему
- Но решает только под linux и выглядит криво
- Завернуть в функцию нельзя, поэтому




* Макросы (13:04)
- Макрос определяет простую текстовую замену
#+begin_src cpp
#define FIRST SECOND
#+end_src
- заменит в тексте все вхождения токена FIRST на SECOND
#+begin_src cpp
int FIRST = 5; // Заменит имя на SECOND
#+end_src
- Но потребуется полный токен или последовательность токенов
#+begin_src cpp
int xFIRST = 5; // Не заменит
#+end_src
- Макросы могут брать аргументы
#+begin_src cpp
#define ADD(X, Y) X + Y
#+end_src
** Неожиданные свойства макросов
- Даже аккуратное определение макросов не спасает
#+begin_src cpp
#define ADD(X, Y) ((X) + (Y))
#+end_src
- Тогда наивное использование кажется безопасным
#+begin_src cpp
int x = ADD(2, 2) * 2; // OK
#+end_src
- Но мы можем улучшить далее
#+begin_src cpp
#define MAX(X, Y) ((X) > (Y) ? (X) : (Y))
int z = MAX(++x, 2); // 10
#+end_src
** Макросы для бенчмаркинга
#+begin_src cpp
#define NOOPT(x) asm(""::"r"(x));
for((int i = 0; i<N; ++i){
    NOOPT(i);
    for(int j = 0; j < M; ++j){
      NOOPT(j);
    }
}
#+end_src
- Здесь удобный макрос NOOPT экранирует защиту от оптимизаций с помощью ассемблерной вставки
- В итоге если мы решили сменить экранирование, нам не придется менять код




* Бенчмаркинг (21:32)
#+begin_src cpp
#pragma once

#include <stdlib.h>
#include <time.h>

#ifdef _MSC_VER
#include <intrin.h>
#include <windows.h>
#endif

const int MICROSEC_AS_NSEC = 1000;
const int SEC_AS_NSEC = 1000000000;
#define SEC_AS_MICROSEC (SEC_AS_NSEC / MICROSEC_AS_NSEC)

static double diff(struct timespec start, struct timespec end){
  struct timespec temp;
  if(end.tv_nsec - start.tv_nsec < 0){
    temp.tv_sec = end.tv_src - start.tv_sec - 1;
    temp.tv_nsrc = SEC_AS_NSEC + end.tv_nsec - start.tv_nsec;
  } else {
    temp.tv_sec = end.tc_sec - start.tv_sec;
    temp.tv_nsec = end.tv_nsec - start.tv_nsec;
  }
  double msec = temp.tv_sec * SEC_AS_MCROSEC + temp.tv_nsec / MICROSEC_AS_NSEC;
  return msec / SEC_AS_MICROSEC;
}
#define NOOPT(x) asm(""::"r,i"(x)) // i для передачи констант

#+end_src
- maybe_readopt(argc, argv, i, &v)




* Загадочный эксперимент (27:45)
- Следующий код вычисляет сумму элементов двумерного массива
#+begin_src cpp
for(j = 0; j < len; ++j)
  for(i = 0; i<ARRSZ; ++i)
    sum +=arr[i][j]; // идем по столбцу
#+end_src
- И этот тоже 
#+begin_src cpp
for(i = 0; i<ARRSZ; ++j)
  for(j = 0; j<len; ++j)
    sum += arr[i][j]; // идем по строке
#+end_src
- Однако разница кратная




* Немного о памяти (34:04)
** Память с произвольным доступом
- Грубо можно классифицировать память на динамическую и статическую
 - DRAM один транзистор и один конденсатор
 - SRAM шесть транзисторов (можно считать бит и его отрицание)
- статическая память быстрее, но намного дороже. Поэтому то, что мы называем "оперативкой" это обычно DRAM
- В современных условиях это DDR, реже SDR
- SRAM используется, чтобы кешировать недалеко от процессора часто используемые данные
- Ядра + кеши = кластер (обычно L1+L2)
** Идея кэширования
- Допустим вы делаете обращение в память
#+begin_src cpp
int b = a[0]; // около 100 наносекунд
#+end_src
- Процессор предполагает что следующее обращение будет недалеко и загружеает всю кэш линию (около 64 байт) в L1 кэш
#+begin_src cpp
int c = a[1]; // около 0.5 наносекунд
#+end_src
- В современных процессорах есть много уровней кэшей и данные, которые не влезают (или вытесняются) из кэша L1 попадают в L2, а потом и в L3
- В итоге чем активнее программа использует данные, тем быстрее у нее к ним доступ
** Иерархия памяти
| Вид памяти | Примерное время доступа | Примерный размер* |
| L1         | 0.5ns                   | 256Kb             |
| L2         | 7ns                     | 1Mb               |
| L3         | 20ns                    | 8Mb               |
| RAM        | 100ns                   | 8Gb               |
| HDD(4kb)   | 150000ns                | 1Tb               |
- *для coffee lake, i5-8300H
- Цена одного branch mispredict приблизительно равна цене одного cache miss с обращением в L2
- Из RAM читают линии, из HDD страницы




* Локальность данных (41:34)
- Двумерные массивы лежат в памяти непрерывным куском
- cache miss - попытка получить данные, которых еще нет в кеше
** Более сложный пример
- Представьте, что у вас есть код, выполняющий перемножение матриц
#+begin_src cpp
void matrix_mult(const int *A, const int *B, const int *C, int AX, int AY, int BY){
  for(int i = 0; i < AX; i++){
    for(int j = 0; j < BY; j++){
      C[i + BY + j] = 0;
      for(int k = 0; k < AY; k++)
        C[i*BY+j] += A[i*AY+k] * B[k*BY+j];
    }
  }
}
#+end_src
- запишем (AB)ij = SUM(k=0 -> N-1)(aik T(bjk))
- Теперь можно заметить, что нелокальность вычислений проистекает из того факта, что обращения к второй матрице проходят в транспонированном виде
- Ради улучшения локальности мы можем завести дополнительную матрицу и транспонировать ее
#+begin_src cpp
size_t bsz = BIG_BY * BIG_AY * sizeof(int);
int *tmp = (int *) malloc(bsz);
for(int i = 0; i < AY; i++)
  for(int j = 0; j < BY; j++)
    tmp[j * AY + i] = B[i * BY + j];
#+end_src
** Клеточное перемножение
- Идея переложить значения из больших матриц в маленькие, довольно локальные блоки, после чего пройти и накопить частичные суммы
- Ульрих Дреппер в своей замечательной статье предлагает этот подход
#+begin_src cpp
int SM = L1_LINE_SIZE / sizeof(int);
for(i=0;  i<AX;  i+=SM)
  for(j=0;  j<BY;  j+=SM)
    for(k=0;  k<AY;  k+=SM)
      for(i2=0, rres=&C[i*BY+j], rmul1=&A[i*AY+k];  
          i2<SM;  
          ++i2, rres+=BY, rmul1+=AY)
        for(k2=0, rmul2=&B[k*BY+j];
            k2<SM;
            ++k2, rmul2+=BY)
          for(j2=0;  j2<SMl  ++j2)
            rres[j2]+=rmul1[k2]*rmul2[j2];
#+end_src





* Время ставить опыты (54:27)
- Задача: выяснить размер кешей
- решение: последовательное обращение и случайное (тяжело интерпретируем: скачок сложно распознать)
** Эффекты кэшей и асимптотика
- плохая кеш-лояльность может снизить производительность в 20-30 раз
- Предположим, что у нас есть выбор между алогоритмом O(n*log(n)) c хорошей локальностью данных и алгоритмом O(n) c плохой локальностью
- Каким должен быть выбор для разных n?




* Кеш как структура данных (01:13:20)
- Есть страницы по 64байта, включая номер
#+begin_src cpp
struct page {
  int index;
  char data[60];
};
#+end_src
- Также существует медленная функция
#+begin_src cpp
void slow_get_page(int n, struct page *p)
#+end_src
- Необходимо завести кэш для обращений к страницам
- Считаем, что всего в кэше места не больше, чем на m страниц, m много меньше n
- Какую структуру данных выбрать для кеша?
- Какую стратегию кэширования выбрать?
- В какой момент страница кэшируется?
- В какой момент страница вытесняется?
- LRU, LFU, Алгоритм Белади 
** Командный проект 
- Problem LC
- Более сложный алгоритм кэширования
- Чек лист на проект (1:26:50)




* Небольшой тизер (01:31:31)
- sum_if_greater для массива unsigned char которые равномерно распределены
- и для такого же, но уже отсортированного массива
- и разница оказывается колоссальной
- Чтобы понять почему, потребуется познакомиться с: конвейером, предсказанием переходов -> (A27)




* Problem
- LC



