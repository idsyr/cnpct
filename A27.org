#+TITLE: Семниар 7.2. Конвейер
#+AUTHOR: idsyr
#+STARTUP: showeverything 
#+OPTIONS: toc:2




* Исполнение программы (00:00)
- Следующий код суммирует все элементы массивы, меньшие, чем 128
- Проблема в том, что для несортированных массивов он (без изменений в самом коде) работает почти в 10 раза медленней, чем для сортированных
- Значит надо понять почему происходит замедление и как это исправить
** Виртуальнв память и загрузка
- ОС создает процесс (единица изоляции памяти) с PID
- Каждому процессу выделяется вирутальная память (все адресное пространство)
- Дальше файл загружается в вирутальную память, для линкера он состоит из секций(кода секция text, данные секция data...), для лоадера(программа ОС которая загружает файл в выделенную виртуальную память) это сегменты 
- маппинг виртуальной памяти на физ - ОС
- rip ставится на ту часть виртуальной памяти где теперь лежит код (сегмент)




* Конвейер (10:45)
| instruction fetch -> | instruction decode, reg fetch -> |
| exec ->              | memory access ->                 |
| registr write back   |                                  |
- Иногда приходится ждать выполнения предыдущей команды
- байпас оптимизация





* Предсказание переходов (15:12)
- Что если в конвейере встретиться инструкция условного перехода?
#+begin_src asm
  mov ecx, DWORD PTR [eax] ;; mem access
  cmp ecx, 128             ;; exec (wait ecx)
  jle L3                   ;; decoded (known to be jump_
  mov ebx, ecx             ;; fetched?
  sar ebx, 31
  add esi, ecx
  adc edi, ebx
L3:
  mov ecx, edx             ;; fetched?
#+end_src
- Ждать / выбрать оба / выбрать один
- Для циклов наиболее вероятен прыжок
- Теперь странности исчезают
#+begin_src cpp
for(j=0; j<len; ++j)
  if(arr[j] > 128)
    sum+=arr[j];
#+end_src
- Вероятность правильного предсказания перехода теперь... а кстати, какая?
- Это очень сильно зависит от конкретного механизма предсказания переходов
- Они работают по разному
- простой: с каждым адресом связано только два бита 
- сейчас это кеш с историей
- И кроме бранч предиктора может быть loop предиктор, потому что это проще и незачем засорять кеш
** Профилировщики
- Существует большое количество программ, которые помогают в анализе производительности, включая микроархитектурные эффекты
- Они также могут помочь и с кещами





* Упражняемся в ассемблере (26:30)
#+begin_src asm
  movsx  rsi, edp
  test edp, edp
  jle .LoopExit
  xor eax, eax
.L1: 
  movsx rdx, DWORD PTR [rbx+rax*4]
  cmp edx, 128
  jle .L2
  add rcx, rdx
.L2:
  add rax, 1
  cmp rsi, rax
  jne .L1
#+end_src



* Хитрая оптимизация (31:08)
#+begin_src cpp
for(j=0; j<len; ++j){
  if(arr[j] > 128)
    sum+=arr[j];
}
#+end_src
- На несортированных 5.6, на сортированных 0.6
#+begin_src cpp
for(j=0; j<len; ++j){
  int tmp = (arr[j] > 128);
  sum +=(arr[j]*tmp);
}
#+end_src
- На несортированных 1.2, на сортированных 1.2 (попугаев)
- Минусы: менее понятно
- Трансформация если бы была всегда позитивной ее бы делал компилятор
- Полученный ассемблер:
#+begin_src asm
  movsx rsi, edp
  test edp, ebp
  jle .LoopExit
  xor edx, edx
.Loop:
  mov ecx, DWORD PTR [rbx+rdx*4]
  xor eax, eax
  cmp ecx, 128
  setg al ;; 1 or 0 in A lower reg
  imul eax, ecx
  cdqe ;; convert double quad word
  add rdx, 1
  cmp rsi, rdx
  jne .Loop
#+end_src




* Out of order (36:50)
- На самом деле инструкции исполняются не так уж линейно
- Важная часть конвейера - планировщик который раскидывает инструкции по ALU, учитывая их специфику и взаимосвязи
- Это делает mispredict еще хуже
- Очень долгая и сложная стадия это доступ к памяти
- Что если бы мы могли заранее туда сбегать пока конвейер делает что то другое
** Prefetch
- Техника предвыборки служит для того, чтобы подкачать в кэш данные
#+begin_src cpp
for(int i=0; i<ARRSZ; ++i){
  a[i] = a[i] + b[i];
  __builtin_prefetch(a[i+1]); // на след итерации понадобится, УЖЕ загрузи
  __builtin_prefetch(b[i+1]);
}
#+end_src
- Здесь до перехода будут подкачены значения для вычисления следующей итерации цикла
- может помочь на некоторых архитектурах




* Время решать задачи (44:00)
** Instruction cache
- Инструкции это тоже данные
- Конвейер декодировав инструкцию сохраняет ее в кэш инструкций
- Таким образом, кроме branch mispredict можно рассматривать isntruction cahce miss
- Но обычно в процессоре достаточно большой кэш инструкций: речь идет о чем то около 32 килобайт на каждое ядро и поэтому наглядно увидеть эффекты на простом приложении сложно
- эксперимент на кэш инструкций?
- L1 свой для инструкций и данных, а L2 ОБЩИЙ




* Загадочный бинарный поиск (46:40)
- Бинарный поиск в массиве из 2^25 элементов
- Бинарный поиск в массиве из 2^25+2^10
- И бинарный поиск на массиве который капельку больше стал работать более чем в полтора раза быстрее




* Реалистичные кеши (52:18)
- Хардверный кеш работает иначе
- Физический адрес на компьютере:
| tag | index | bank | offset |
- bank - номер банка кешей - way
- index - определяет номер set (размер кеша для данного индекса):
| way | way | way | way  | another way |
| set | V   | tag | data | same 3f     |
|     | V   | tag | data |             |
- количество way - размер кеша
- сколько бит в индексе столько setов в way
- tag определяет свойства для вытеснения
- За каждую кеш линию конкурируют блоки c _определенной переиодичностью_
- это сет ассоциотивный кеш, он самый простой, дешевый, его как правило все используют




* Разгадка: ассоциативность (01:02:30)
- Бинарный поиск будет использовать элементы: 2^25,24,23. И таким образом будет использоваться одна и та же кеш линия, которая на каждом шаге будет вытесняться, с оффсетом вытеснения происходить не будет, будут использоваться разные set 
- Бинарный поиск с небольшим смещением будет попадать в разные кеш-линии из-за ассоциативности кеша




* Бонус про замеры кешей (1:10:28)
- не говоря про вызов функций и использование нескольких доп операций в бенчмарке: Даже циклы вокруг замеров доступа к L1 кешу нужно вычитать, они могут быть в разы больше по времени (10x например)



